p(c|w) = p(w|c)*p(c)/p(w)
而p(w)是没有必要求解的

对于种类c1和c2,共享一个词集c
有p(c1)=n(c1)/n(c) p(c2)=n(c2)/n(c)
以c1举例:p(w|c1)=∏p(wi|c1)
p(wi|c1)=n(wi)/n(c1)
需要注意的是在这里对于字wi,词集c1是扁平化的
这无疑是很蠢的,因为要避免对于wi有相同的概率,尤其是在wi可以出现多个的时候
对于某些中性词,c1和c2都可以出现
这样,种类c1和c2就不是互相独立的,也不能说是扁平的了,因为n(c1)和n(c2)是动态的
像是没有训练直接的运用词集,或者说
朴素贝叶斯作用于训练过程,不是,
这里是指在已经分好类的前提下,可以对未被分类的词向量进行分类
已经分好类的词集的概率是多少?

在离散型变量下,概率是由样本和样本总体共同决定的,唯一的经验规则就是对类别的分取,
所以关键在三者:样本,样本总体和样本分类,奇怪的是,这里的轨迹不是样本的量子轨迹,而是总览轨迹
我一般把它称作频率,在样本足够多时,可以以频率估计概率
"在相同的条件下，进行了n次试验，在这n次试验中，事件A发生的次数m称为事件A发生的频数"
可以将顺概率称作频率,逆概率称作概率
这里t:1——>2的分布是未知的,所以要用频率估计概率(实时分布)
而对于p(c)的求解,我更倾向于它写错了,以非独立扁平化词集求解更合适
如果用独立扁平化词集,会有一部分中性词无法归入某一类
加上一用有词相当于x/y+1,而x/y+1 < x/y,对概率有稀释作用,难搞

